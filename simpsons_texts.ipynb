{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d3812c5-b869-4a5b-a62b-0dcdee78ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a24319-c63d-4e30-9098-7e8d2056cc05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b38e4d-6b1a-49c7-8a94-d37ba9035576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from a sentece and lemmatize it\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# stopwords = stopwords.words()\n",
    "\n",
    "def clean_sentence(sentence, lemmatizer, stopwords_list):\n",
    "    # remove special characters and lower letters\n",
    "    sentence = re.sub(\"[^A-Za-z0-9]+\", ' ', sentence).lower()\n",
    "    sentence_new = []\n",
    "\n",
    "    for word in sentence.split():\n",
    "        if word not in stopwords_list and len(word) > 1:\n",
    "            sentence_new.append(lemmatizer.lemmatize(word))\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    if len(sentence_new) > 2:\n",
    "        return ' '.join(sentence_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead6142-0948-4362-a14e-1a8fa48902e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00abc1d1-ac63-425d-b4a0-b721dd0f37a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131853, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/simpsons_dataset.csv')\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b032b56e-d5c3-48cf-91b1-d6c19743edf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76aa6757-d40b-40ad-989b-0ed320a47fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.02401065826416\n"
     ]
    }
   ],
   "source": [
    "# lemmatization of words, removing special characters, lower words and remove stopwords\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords_list = stopwords.words()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "spoken_words = df.spoken_words.apply(lambda x: clean_sentence(x, lemmatizer, stopwords_list))\n",
    "spoken_words.dropna(inplace = True)\n",
    "spoken_words.drop_duplicates(inplace = True)\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "701cbc09-61f2-4221-aa2b-eb2a09441051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90002,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spoken_words.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af627fd4-7da7-4f9c-b06d-ca795c5412a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## tfidf version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66c06de8-7304-4c26-aebf-b77cc1344739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using tf idf in order to remove frequent words\n",
    "\n",
    "sentences = spoken_words.values\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "08035652-8f88-4ae4-89e3-187392299eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument percentage indicates how many percent of the most important words we want to keep in each sentece (values between 0 and 1)\n",
    "# sentences is a list of strings\n",
    "\n",
    "def remove_frequent_words(sentences, percentage):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(sentences)\n",
    "    \n",
    "    # vectors[i, j] is a tf-ids value for word feature_names[j] for sentence sentences[i]\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    \n",
    "    new_sentences = []\n",
    "    \n",
    "    for i in range(vectors.shape[0]):\n",
    "        # vector form of a sentence\n",
    "        sentence_vector = vectors[i].toarray()[0]\n",
    "        indexes = np.where(sentence_vector != 0)[0]\n",
    "        # words which occurs in a sentence with corresponding tf-idf values\n",
    "        words_values = np.array([[feature_names[index], sentence_vector[index]] for index in indexes])\n",
    "        # sort words by their tf-idf value and take only a percentage of words with the biggest tf-idf value\n",
    "        try:\n",
    "            new_sentence = words_values[words_values[:,1].argsort()][:,0]\n",
    "            new_sentence = new_sentence[- int(len(new_sentence) * percentage) : ]\n",
    "            # new_sentence = ' '.join(new_sentence)\n",
    "        except:\n",
    "            new_sentence = sentences[i].split()\n",
    "        \n",
    "        new_sentences.append(new_sentence)\n",
    "        \n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d48eec4e-6009-40fe-a9e2-c08d3976fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = remove_frequent_words(sentences, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "277f1114-7bf1-42d6-bdf0-4975790b872e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['say' 'anything' 'left']\n",
      "think anything left say\n"
     ]
    }
   ],
   "source": [
    "i = 4\n",
    "\n",
    "print(new_sentences[i])\n",
    "print(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "681501c3-b553-4d75-b0f0-f40cefd6ed45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "think 2653\n",
      "anything 752\n",
      "left 557\n",
      "say 2398\n"
     ]
    }
   ],
   "source": [
    "for word in sentences[i].split():\n",
    "    no_occurances = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        no_occurances += len(np.where(np.array(sentence.split()) == word)[0])\n",
    "\n",
    "    print(word, no_occurances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de6e6b-5e27-40b2-abf8-faaff94621b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f3af68-cb27-4967-8679-25063e9b6859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48cbdcb5-924c-46a5-a3b9-60b68e22066f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## tfidf version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "161fb506-c3ef-4eb0-a49f-020f874e052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose we have given a list of documents (each document is just a single string)\n",
    "# bow argument is a bag of words for a single document\n",
    "# word_dict is dictionary with all words from all documents as keys and \n",
    "# values indicates how many times these words appears in a single document for which we have given bow\n",
    "# it returns a dictionary with values indicating tf value for each word in a word_dict and for given document\n",
    "\n",
    "def computeTF(bow, word_dict):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in word_dict.items():\n",
    "        tfDict[word] = count / float(bowCount)\n",
    "\n",
    "    return tfDict\n",
    "\n",
    "\n",
    "def computeIDF(word_dict_List):\n",
    "    N = len(word_dict_List)\n",
    "    \n",
    "    # count the number of documents that contain a word w\n",
    "    idfDict = dict.fromkeys(word_dict_List[0].keys(), 0)\n",
    "    for doc in word_dict_List:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "                \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "        \n",
    "    return idfDict\n",
    "\n",
    "# computing tf-idf values for each document in a documents_list\n",
    "# it returns a list with dictionaries, i-th dictionary contains words which appears in all documents as keys \n",
    "# and values indicates tf-idf values for given word for i-th document\n",
    "\n",
    "def computeTFIDF(documents_list):\n",
    "    # word set is a set with words from all documents\n",
    "    word_set = set()\n",
    "    for doc in documents_list:\n",
    "        bow = doc.split()\n",
    "        word_set = word_set.union(set(bow))\n",
    "    \n",
    "    # list of tf values for each document\n",
    "    tf_documents = []\n",
    "    # word_dict_List will be used to calculate idf\n",
    "    word_dict_List = []\n",
    "    \n",
    "    # calculating tf values for each document\n",
    "    for doc in documents_list:\n",
    "        # bag of words for a document\n",
    "        bow = doc.split()\n",
    "        # word_dict is a dictionary which indicates how many times each word (from word_set) appears in a document\n",
    "        word_dict = dict.fromkeys(word_set, 0)\n",
    "        for word in bow:\n",
    "            word_dict[word] += 1\n",
    "            \n",
    "        word_dict_List.append(word_dict)\n",
    "        tf_documents.append(computeTF(bow, word_dict))\n",
    "        \n",
    "    # calculating idf for each word\n",
    "    idfs =  computeIDF(word_dict_List)\n",
    "    \n",
    "    # calculating tf-idf values for all words in each document\n",
    "    tfidf_list = []\n",
    "    \n",
    "    for tfDict in tf_documents:\n",
    "        tfidf = {}\n",
    "        for word, val in tfDict.items():\n",
    "            tfidf[word] = val * idfs[word]\n",
    "            \n",
    "        tfidf_list.append(tfidf)\n",
    "        \n",
    "    return tfidf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05b47157-3c5c-407d-ba05-df54a143a223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "doc_list = spoken_words.values[:2]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "tf_idfs = computeTFIDF(doc_list)\n",
    "\n",
    "print(start_time - time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f26d42de-6168-4721-ab22-88f747d3cd7d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'show': 0.0,\n",
       "  'sometimes': 0.07701635339554948,\n",
       "  'disease': 0.07701635339554948,\n",
       "  'think': 0.07701635339554948,\n",
       "  'little': 0.07701635339554948,\n",
       "  'lesson': 0.0,\n",
       "  'teachshow': 0.0,\n",
       "  'like': 0.0,\n",
       "  'actually': 0.07701635339554948,\n",
       "  'talk': 0.0,\n",
       "  'although': 0.0,\n",
       "  'natural': 0.07701635339554948,\n",
       "  'news': 0.07701635339554948,\n",
       "  'touch': 0.0,\n",
       "  'magazine': 0.07701635339554948,\n",
       "  'know': 0.0,\n",
       "  'plan': 0.0,\n",
       "  'sure': 0.0},\n",
       " {'show': 0.0,\n",
       "  'sometimes': 0.0,\n",
       "  'disease': 0.0,\n",
       "  'think': 0.0,\n",
       "  'little': 0.0,\n",
       "  'lesson': 0.06931471805599453,\n",
       "  'teachshow': 0.06931471805599453,\n",
       "  'like': 0.06931471805599453,\n",
       "  'actually': 0.0,\n",
       "  'talk': 0.06931471805599453,\n",
       "  'although': 0.06931471805599453,\n",
       "  'natural': 0.0,\n",
       "  'news': 0.0,\n",
       "  'touch': 0.06931471805599453,\n",
       "  'magazine': 0.0,\n",
       "  'know': 0.06931471805599453,\n",
       "  'plan': 0.06931471805599453,\n",
       "  'sure': 0.06931471805599453}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da4dcf3e-7e03-4466-8a35-7b415e60d79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['actually little sometimes disease magazine news show natural think',\n",
       "       'know although sure like talk touch lesson plan teachshow show'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4674b2b4-5997-4655-8ca9-a94b8334acc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f54c43-1e94-49e2-af4b-bc389dad11b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb095295-fffb-48f1-82b0-a69953d6fb10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## word embeddings model with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "393aa7f9-0717-4356-9c36-a3236ad9f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding phrases in spoken_words\n",
    "\n",
    "sent = [row.split() for row in spoken_words]\n",
    "# the bigger threshold parameter, the fewer phrases, it depends on min_count also\n",
    "phrases = Phrases(sent, min_count = 30, threshold = 10)\n",
    "# use Phraser to cut down memory consumption\n",
    "bigram = Phraser(phrases)\n",
    "sentences = list(bigram[sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab909dbb-457c-4a72-955b-36b4cbae2642",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'capital_city': 156.57407407407408,\n",
       " 'feel_like': 10.07566438138214,\n",
       " 'little_girl': 21.5048803764934,\n",
       " 'let_go': 12.686611423893615,\n",
       " 'last_year': 11.496963931764087,\n",
       " 'dr_hibbert': 467.58712121212125,\n",
       " 'last_night': 43.36695329229122,\n",
       " 'good_lord': 13.496176933223298,\n",
       " 'next_week': 30.333402061855672,\n",
       " 'homer_simpson': 20.336465149180203,\n",
       " 'mr_simpson': 31.12648738301149,\n",
       " 'young_lady': 12.761946516365196,\n",
       " 'uh_huh': 20.25305448597987,\n",
       " 'wait_wait': 28.819873624765414,\n",
       " 'wait_minute': 113.8391940450399,\n",
       " 'five_hundred': 30.95109373305866,\n",
       " 'little_bit': 19.135373009220455,\n",
       " 'god_bless': 22.764261126137203,\n",
       " 'go_ahead': 36.55549802231905,\n",
       " 'haw_haw': 640.7076124567474,\n",
       " 'hee_hee': 1089.696016296967,\n",
       " 'look_like': 11.149331297707505,\n",
       " 'three_hundred': 12.484653792104927,\n",
       " 'let_see': 13.553745928338762,\n",
       " 'comic_book': 199.39813266124412,\n",
       " 'ooh_ooh': 13.553097270393225,\n",
       " 'leave_alone': 31.102659574468085,\n",
       " 'hundred_dollar': 59.83576674500587,\n",
       " 'woo_hoo': 814.1322293623331,\n",
       " 'patty_selma': 24.966561046315647,\n",
       " 'smell_like': 10.407974419129163,\n",
       " 'chief_wiggum': 245.3947549506843,\n",
       " 'montgomery_burn': 184.1124289772727,\n",
       " 'mr_burn': 101.3657530344315,\n",
       " 'million_dollar': 163.30297297297295,\n",
       " 'heh_heh': 444.32714109442423,\n",
       " 'bart_simpson': 11.682860150288004,\n",
       " 'ow_ow': 266.0065938145661,\n",
       " 'blah_blah': 1651.288644470868,\n",
       " 'never_seen': 29.757482377747895,\n",
       " 'thousand_dollar': 158.17867295088004,\n",
       " 'year_ago': 102.39826108328981,\n",
       " 'eight_year': 19.1108322741564,\n",
       " 'every_day': 20.460165745856354,\n",
       " 'lisa_simpson': 11.795795508838989,\n",
       " 'happy_birthday': 42.78193664656547,\n",
       " 'mom_dad': 13.597285206887767,\n",
       " 'oh_god': 16.177880138822267,\n",
       " 'five_minute': 25.68559007033617,\n",
       " 'bye_bye': 173.59171874999998,\n",
       " 'doo_doo': 838.2277048438207,\n",
       " 'troy_mcclure': 1246.2995192307692,\n",
       " 'good_morning': 15.738856589147288,\n",
       " 'ten_year': 36.67286559727123,\n",
       " 'sound_like': 18.662140035004615,\n",
       " 'best_friend': 57.214643697180506,\n",
       " 'ice_cream': 849.3961508788757,\n",
       " 'two_hundred': 17.082742049114334,\n",
       " 'get_rid': 31.061259267139093,\n",
       " 'five_dollar': 18.7198726157579,\n",
       " 'field_trip': 73.47797619047618,\n",
       " 'fat_tony': 314.90561224489795,\n",
       " 'principal_skinner': 494.90972350230413,\n",
       " 'please_please': 15.263079123414071,\n",
       " 'thank_god': 29.577694270619105,\n",
       " 'fourth_grade': 44.74193548387097,\n",
       " 'get_outta': 15.194117976166053,\n",
       " 'krusty_clown': 140.5856644601039,\n",
       " 'springfield_elementary': 101.7958839769101,\n",
       " 'old_fashioned': 60.578088578088575,\n",
       " 'nuclear_power': 80.60560110280781,\n",
       " 'dear_lord': 28.333735008894244,\n",
       " 'phone_call': 11.03812220566319,\n",
       " 'power_plant': 78.90532670454544,\n",
       " 'lady_gentleman': 165.34470241099507,\n",
       " 'kent_brockman': 1214.3772071435778,\n",
       " 'twenty_five': 39.768533212423485,\n",
       " 'year_old': 29.202467049678944,\n",
       " 'santa_little': 26.66169218189953,\n",
       " 'whoa_whoa': 188.93619739510643,\n",
       " 'ten_thousand': 12.800052998139305,\n",
       " 'hot_dog': 64.47007416176316,\n",
       " 'ten_minute': 12.867478477480537,\n",
       " 'wish_could': 11.041236882876264,\n",
       " 'someone_else': 50.656131138860694,\n",
       " 'nyah_nyah': 256.4605263157895,\n",
       " 'high_school': 56.98655081146516,\n",
       " 'mr_krabappel': 56.17507795162785,\n",
       " 'yes_yes': 12.882996254681649,\n",
       " 'nuclear_plant': 72.73396037011173,\n",
       " 'mmm_hmm': 29.73097302504817,\n",
       " 'channel_six': 53.50415372390378,\n",
       " 'even_though': 51.33137738937586,\n",
       " 'fifty_dollar': 16.248201123201124,\n",
       " 'could_use': 12.407240899144618,\n",
       " 'new_york': 170.24848421764813,\n",
       " 'super_bowl': 253.44577294685988,\n",
       " 'good_luck': 36.38862464845399,\n",
       " 'pork_chop': 814.5492537313432,\n",
       " 'malibu_stacy': 1251.9574036511156,\n",
       " 'united_state': 126.56493506493507,\n",
       " 'five_year': 10.986036766819012,\n",
       " 'thirty_year': 10.26682376661836,\n",
       " 'twenty_four': 20.53014098201264,\n",
       " 'last_week': 24.52564074262125,\n",
       " 'rest_life': 15.827716636392777,\n",
       " 'sideshow_bob': 720.1707543610136,\n",
       " 'big_deal': 38.57459810423249,\n",
       " 'tap_tap': 237.3523473802275,\n",
       " 'ever_seen': 20.850476915943567,\n",
       " 'miss_hoover': 127.37337853773585,\n",
       " 'kwik_mart': 2342.3719165085386,\n",
       " 'itchy_scratchy': 1280.3076923076924,\n",
       " 'credit_card': 115.29545454545455,\n",
       " 'yi_yi': 700.054820415879,\n",
       " 'bad_news': 19.341864048259474,\n",
       " 'important_thing': 11.788043050858883,\n",
       " 'parking_lot': 10.648982056590752,\n",
       " 'ninety_nine': 62.379955081414934,\n",
       " 'little_helper': 66.51820141300443,\n",
       " 'disco_stu': 154.49687108886107,\n",
       " 'ding_ding': 399.33526124889715,\n",
       " 'cell_phone': 438.79636363636365,\n",
       " 'duck_duck': 631.191380569759,\n",
       " 'frontline_infantry': 341.3170506912442}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check what phrases a model has found\n",
    "print(len(bigram.find_phrases(sent)))\n",
    "bigram.find_phrases(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad18f981-115e-43dc-94c0-f3c3f200384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(sentences,\n",
    "                     min_count=20,\n",
    "                     window=2,\n",
    "                     vector_size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e4b5058-f055-40e2-97c2-fa60dd89be80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6809110, 17400750)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentences, total_examples = w2v_model.corpus_count, epochs = 30, report_delay = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d626c3ff-075c-41af-af6b-c24fe28fe605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('homer', 0.5787737369537354),\n",
       " ('abe', 0.5406563878059387),\n",
       " ('homie', 0.5033149719238281),\n",
       " ('badly', 0.498450368642807),\n",
       " ('livin', 0.48590725660324097),\n",
       " ('mom', 0.4801368713378906),\n",
       " ('settled', 0.47922274470329285),\n",
       " ('sorry', 0.47424599528312683),\n",
       " ('fault', 0.4683988690376282),\n",
       " ('sweetheart', 0.4633442461490631)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('marge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3780293-9f0a-411e-b609-8e214e6068b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.82764927e-02, -1.04250707e-01, -9.59689766e-02,  7.13768229e-02,\n",
       "        2.44302392e-01, -2.89452463e-01,  2.62507141e-01,  3.25873405e-01,\n",
       "        2.52810687e-01, -7.94884488e-02, -1.10158287e-01, -2.13204414e-01,\n",
       "       -1.26720360e-02, -2.02310309e-01, -7.16938227e-02,  3.05563654e-03,\n",
       "        1.90176740e-01,  2.48435184e-01,  1.26867741e-01, -1.76872879e-01,\n",
       "        1.51332229e-01, -1.70148730e-01, -1.43923024e-02,  9.82186347e-02,\n",
       "        3.65428701e-02,  1.41942948e-01, -1.07179031e-01,  1.94095522e-01,\n",
       "       -2.97538415e-02, -1.40040785e-01,  1.97938114e-01,  1.43576384e-01,\n",
       "        3.50714549e-02, -3.54532897e-02, -8.84125102e-03, -7.70406872e-02,\n",
       "       -5.39456494e-02, -7.72691816e-02,  7.70236403e-02,  7.00644404e-02,\n",
       "       -2.37879232e-02, -2.87032891e-02, -3.30884866e-02, -4.17106152e-02,\n",
       "        2.98272640e-01,  1.99935794e-01,  5.96361868e-02, -1.81941882e-01,\n",
       "       -1.55064955e-01,  7.60004818e-02, -1.28048226e-01, -5.84208332e-02,\n",
       "       -1.85599953e-01, -5.11784405e-02, -1.60390735e-01,  2.08574504e-01,\n",
       "       -5.66193871e-02, -5.19705638e-02, -3.96021977e-02, -1.39285609e-01,\n",
       "        1.51418790e-01,  7.76051134e-02, -3.04687738e-01,  7.04431012e-02,\n",
       "        2.75781341e-02, -8.44400078e-02,  1.29431195e-03,  3.09548099e-02,\n",
       "       -4.76481505e-02, -2.27746278e-01,  6.95327744e-02,  8.49364176e-02,\n",
       "        1.68834031e-01, -2.31654286e-01,  4.20296565e-02,  2.18518183e-01,\n",
       "       -4.43647623e-01,  7.02370256e-02,  9.23387036e-02,  1.03370629e-01,\n",
       "        1.00312263e-01, -2.82939762e-01,  8.61478224e-02, -9.33581218e-02,\n",
       "        1.51212096e-01,  1.18794806e-01, -3.04178596e-01,  1.77317169e-02,\n",
       "        2.59315610e-01,  8.07290375e-02,  1.13124855e-01,  1.26344087e-02,\n",
       "        1.51501253e-01, -5.97506091e-02,  2.72506237e-01,  7.07322583e-02,\n",
       "        1.45250276e-01, -5.14910556e-02,  7.94567019e-02, -1.91794578e-02,\n",
       "       -5.28774522e-02, -1.99177459e-01,  1.83486059e-01, -1.93629414e-01,\n",
       "        2.58933187e-01, -1.14620537e-01, -8.16292465e-02,  5.34513183e-02,\n",
       "       -2.86072522e-01, -6.61022663e-02,  9.50092897e-02, -6.11602655e-03,\n",
       "        2.22751256e-02,  9.96055827e-02, -6.33904338e-02,  1.79258898e-01,\n",
       "       -2.20526412e-01, -8.49561393e-02,  4.66394693e-01,  5.16446941e-02,\n",
       "       -5.04517443e-02, -1.51117211e-02,  1.12407476e-01,  1.96319219e-04,\n",
       "       -7.38733262e-03,  6.50312081e-02,  1.96151901e-02,  2.87951138e-02,\n",
       "       -3.86561491e-02,  1.91860110e-01, -7.78096542e-02,  3.98500532e-01,\n",
       "        5.87321408e-02, -2.12479115e-01,  1.93727449e-01, -4.68198508e-02,\n",
       "       -6.15899898e-02, -1.85110420e-01,  5.66455126e-02, -5.30223362e-03,\n",
       "        1.00133866e-01, -1.95184425e-01,  7.30000436e-02, -9.20316391e-03,\n",
       "       -4.59200353e-04,  1.67279944e-01, -3.28453064e-01,  2.08288189e-02,\n",
       "        2.05832466e-01,  3.07848714e-02,  6.25742227e-02, -8.62205476e-02,\n",
       "       -1.99988082e-01, -1.87982786e-02, -1.35422871e-01,  7.17858672e-02,\n",
       "       -9.83291715e-02, -1.63660079e-01,  4.22825702e-02, -2.31004581e-02,\n",
       "       -5.06045250e-03,  2.18698964e-01, -2.97771215e-01,  4.04729247e-01,\n",
       "       -2.59853810e-01,  1.34656250e-01, -9.61079597e-02,  1.03686601e-01,\n",
       "        2.45470442e-02,  1.37860358e-01, -1.12404048e-01,  6.99932724e-02,\n",
       "        4.35118787e-02, -2.31864285e-02,  1.09346889e-01,  1.15827508e-01,\n",
       "       -4.36591394e-02, -1.94396004e-01, -7.04222620e-02,  1.29938290e-01,\n",
       "       -8.02147537e-02, -1.41348600e-01,  3.80764119e-02, -6.39486089e-02,\n",
       "        1.97996441e-02,  2.17873529e-01,  1.98503956e-01,  2.49351218e-01,\n",
       "        9.09708291e-02, -2.24597797e-01, -2.66852081e-01,  6.38029203e-02,\n",
       "       -2.69958854e-01,  3.25067379e-02,  1.76098511e-01, -7.66339004e-02,\n",
       "        4.12421636e-02,  2.54441556e-02,  7.23367259e-02,  1.23916030e-01,\n",
       "       -3.45774055e-01,  1.61438510e-01, -7.52149299e-02, -5.44322245e-02,\n",
       "       -4.10494395e-02,  1.99788928e-01, -1.36974789e-02, -5.37202917e-02,\n",
       "       -2.16815948e-01, -4.93112057e-02,  1.56544130e-02, -4.06855205e-03,\n",
       "       -1.93387657e-01, -6.39568791e-02, -1.25929713e-02, -2.69176900e-01,\n",
       "        1.58349238e-02, -2.31147259e-01,  8.22632611e-02, -5.42851910e-02,\n",
       "        2.33999804e-01, -1.52729023e-02,  7.33709261e-02, -1.78592399e-01,\n",
       "       -4.62523103e-02, -1.89206213e-01, -4.52479646e-02, -1.02122270e-01,\n",
       "       -7.09856376e-02,  1.62605509e-01,  1.45268291e-01, -1.08100235e-01,\n",
       "       -3.09214788e-03,  8.23881775e-02, -1.65132448e-01, -6.62422776e-02,\n",
       "        1.79140680e-02, -1.66944876e-01,  2.79789567e-02, -1.29483491e-01,\n",
       "        1.65865242e-01, -7.45090619e-02, -1.25093743e-01,  1.72022864e-01,\n",
       "       -1.06234744e-01, -3.91722858e-01,  6.95595145e-02,  2.06234753e-01,\n",
       "        1.01783380e-01,  7.91801587e-02,  6.62875101e-02, -7.54590482e-02,\n",
       "       -7.40303099e-02, -1.21094652e-01, -2.55002886e-01,  1.19914412e-02,\n",
       "       -1.14513293e-01, -1.66801259e-01, -1.73927203e-01, -1.56027883e-01,\n",
       "       -2.07411628e-02,  1.96164891e-01,  5.74728809e-02, -1.40050232e-01,\n",
       "        8.97661448e-02, -2.70529720e-03,  1.58529729e-01,  1.82338595e-01,\n",
       "       -9.63671952e-02, -5.22675402e-02,  4.16024029e-03, -1.19909607e-01,\n",
       "       -1.51772723e-02, -6.94042817e-02,  3.41507457e-02, -1.52261481e-01,\n",
       "        9.55032706e-02,  1.99465938e-02,  1.08384237e-01, -1.41039863e-01,\n",
       "        2.90440232e-01, -1.64516851e-01, -1.28964975e-01,  1.76205143e-01,\n",
       "        7.97437876e-02, -2.10933924e-01, -1.48157850e-01, -1.98908016e-01,\n",
       "        8.41212571e-02,  6.32126480e-02,  1.43195719e-01,  2.38107085e-01,\n",
       "        1.31253496e-01,  8.54902901e-03,  1.69498503e-01,  1.68926418e-02,\n",
       "        1.33017182e-01, -3.56657282e-02, -1.10704033e-02,  9.64682475e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv['badly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8fdf87-c503-40f2-afc3-279743abe920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
